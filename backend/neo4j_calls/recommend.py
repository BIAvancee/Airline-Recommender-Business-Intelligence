# -*- coding: utf-8 -*-
"""clean_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_z7b5p2A8gnGgaPTAM0bzUAH_MyIYbSL
"""

import pandas as pd
import numpy as np
import csv
from scipy.sparse import csr_matrix
import matplotlib.pyplot as plt
import sys 
from surprise import KNNWithMeans
from surprise import Reader
from surprise import Dataset
import scipy.sparse as sp
from neo4j import GraphDatabase

driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "12345600"))
session = driver.session()
nodes=session.run("MATCH (x:User) RETURN x.name as name, x.airline as airline, x.airline_sentiment as airline_sentiment")
df = pd.DataFrame (nodes, columns = ['name','airline','airline_sentiment'])
# column_name=["_unit_id,_golden", "_unit_state","_trusted_judgments","_last_judgment_at","airline_sentiment","airline_sentiment:confidence", "negativereason","negativereason:confidence","airline", "airline_sentiment_gold", "name","negativereason_gold","retweet_count","text","tweet_coord", "tweet_created","tweet_id","tweet_location","user_timezone"]
# with open("/home/fatmach/Documents/Airline-Recommender-Business-Intelligence/backend/data/Airline-Sentiment-2-w-AA.csv", encoding="utf8", errors='ignore') as f:
#   write=csv.DictReader(f)
#   l=list(write)
# df=pd.DataFrame(l)
# data=sys.argv[2]

#print(f'The shape of the dataset set is: {df.shape}')

##ajout de colonne id_user
#print(df)

column_name=["_unit_id,_golden", "_unit_state","_trusted_judgments","_last_judgment_at","airline_sentiment","airline_sentiment:confidence", "negativereason","negativereason:confidence","airline", "airline_sentiment_gold", "name","negativereason_gold","retweet_count","text","tweet_coord", "tweet_created","tweet_id","tweet_location","user_timezone"]


"""**Colonnes** **Ã ** **supprimer**"""



airlines= ['US Airways','United','American','Southwest','Delta','Virgin America']

for i in airlines:
    indices= airlines.index(i)
    plt.subplot(2,3,indices+1)
    new_df=df[df['airline']==i]
    count=new_df['airline_sentiment'].value_counts()
    Index = [1,2,3]
    plt.bar(Index,count, color=['red', 'green', 'blue'])
    plt.xticks(Index,['negative','neutral','positive'])
    plt.ylabel('Mood Count')
    plt.xlabel('Mood')
    plt.title('Count of Moods of '+i)

"""### Recommendation"""

cleanup_nums = {"airline_sentiment":     {"positive": 3, "negative": 1, "neutral": 2},
               }

df = df.replace(cleanup_nums)

matrice=df.dropna(axis=0, subset=['airline', 'airline_sentiment'])

df_pivot=df.pivot_table(index= 'name',columns='airline', values='airline_sentiment') 
df_p=df_pivot.replace (np.nan, '?')
matrice=df_p.to_numpy()
Unique_values_names=df_pivot.index.tolist()
Unique_values_airlines=[a for a in df_pivot.columns.values]

"""### Remplir les cases NAN



"""




# To use item-based cosine similarity

sim_options = {
    "name": "cosine",
    "user_based": False,  # Compute  similarities between items
}
algo = KNNWithMeans(sim_options=sim_options)


reader = Reader(rating_scale=(1, 3))

# Loads Pandas dataframe
data = Dataset.load_from_df(df[["name", "airline", "airline_sentiment"]], reader)


trainingSet = data.build_full_trainset()
algo.fit(trainingSet)
prediction = algo.predict('10Eshaa', 'Americain')

L=Unique_values_names
Ll=Unique_values_airlines
#print(L.index("cairdin"))
for i in L:
  for j in Ll:
    if matrice[L.index(i)][Ll.index(j)] == "?":
      pred=algo.predict(i, j)
      matrice[L.index(i)][Ll.index(j)] =pred.est

matrice2=np.array(matrice,dtype=float)
dataframe= pd.DataFrame(matrice2, columns=Unique_values_airlines,index =Unique_values_names)
df_matrix=sp.csr_matrix(dataframe.values)

def best_airline(user):
  l=[]
  for j in Ll:
    if matrice[L.index(user)][Ll.index(j)] > 2:
      l.append(j)
  if l==[]:
    d=dict(dataframe.mean())
    max_key = max(d, key=lambda key: d[key])
    l=max_key
  return l
# user=sys.argv[1]
vari=best_airline("zupshawrl")
print(vari)


